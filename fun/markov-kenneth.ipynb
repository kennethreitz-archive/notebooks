{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"markov-kenneth.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"kernel_info":{"name":"python3"},"language_info":{"name":"python","version":"3.8.1-final","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"nteract":{"version":"0.12.3"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Collecting twitter-scraper\n  Downloading https://files.pythonhosted.org/packages/8e/45/5956a93dea033407dfd160497f7965ec3785b15b1f8cfbf3c3327e768b08/twitter_scraper-0.3.0-py2.py3-none-any.whl\nCollecting requests-html (from twitter-scraper)\n  Downloading https://files.pythonhosted.org/packages/24/bc/a4380f09bab3a776182578ce6b2771e57259d0d4dbce178205779abdc347/requests_html-0.10.0-py3-none-any.whl\nCollecting w3lib (from requests-html->twitter-scraper)\n  Downloading https://files.pythonhosted.org/packages/6a/45/1ba17c50a0bb16bd950c9c2b92ec60d40c8ebda9f3371ae4230c437120b6/w3lib-1.21.0-py2.py3-none-any.whl\nCollecting bs4 (from requests-html->twitter-scraper)\n  Downloading https://files.pythonhosted.org/packages/10/ed/7e8b97591f6f456174139ec089c769f89a94a1a4025fe967691de971f314/bs4-0.0.1.tar.gz\nCollecting parse (from requests-html->twitter-scraper)\n  Downloading https://files.pythonhosted.org/packages/4a/ea/9a16ff916752241aa80f1a5ec56dc6c6defc5d0e70af2d16904a9573367f/parse-1.14.0.tar.gz\nRequirement already satisfied: requests in /usr/local/anaconda3/lib/python3.7/site-packages (from requests-html->twitter-scraper) (2.22.0)\nCollecting pyppeteer>=0.0.14 (from requests-html->twitter-scraper)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/16/a5e8d617994cac605f972523bb25f12e3ff9c30baee29b4a9c50467229d9/pyppeteer-0.0.25.tar.gz (1.2MB)\n\u001b[K     |████████████████████████████████| 1.2MB 4.9MB/s \n\u001b[?25hCollecting pyquery (from requests-html->twitter-scraper)\n  Downloading https://files.pythonhosted.org/packages/78/43/95d42e386c61cb639d1a0b94f0c0b9f0b7d6b981ad3c043a836c8b5bc68b/pyquery-1.4.1-py2.py3-none-any.whl\nCollecting fake-useragent (from requests-html->twitter-scraper)\n  Downloading https://files.pythonhosted.org/packages/d1/79/af647635d6968e2deb57a208d309f6069d31cb138066d7e821e575112a80/fake-useragent-0.1.11.tar.gz\nRequirement already satisfied: six>=1.4.1 in /usr/local/anaconda3/lib/python3.7/site-packages (from w3lib->requests-html->twitter-scraper) (1.12.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/anaconda3/lib/python3.7/site-packages (from bs4->requests-html->twitter-scraper) (4.8.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.7/site-packages (from requests->requests-html->twitter-scraper) (2019.9.11)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/anaconda3/lib/python3.7/site-packages (from requests->requests-html->twitter-scraper) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/anaconda3/lib/python3.7/site-packages (from requests->requests-html->twitter-scraper) (1.24.2)\nRequirement already satisfied: idna<2.9,>=2.5 in /usr/local/anaconda3/lib/python3.7/site-packages (from requests->requests-html->twitter-scraper) (2.8)\nCollecting pyee (from pyppeteer>=0.0.14->requests-html->twitter-scraper)\n  Downloading https://files.pythonhosted.org/packages/ad/d8/5608d571ffad3d7de0192b0b3099fe3f38d87c0817ebff3cee19264f0bc2/pyee-6.0.0-py2.py3-none-any.whl\nCollecting websockets (from pyppeteer>=0.0.14->requests-html->twitter-scraper)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/c2/6d7eaf91c81328c31b9d98fe97df3fa657b2d7d2610d8a14fc27ec48dafc/websockets-8.1-cp37-cp37m-macosx_10_6_intel.whl (66kB)\n\u001b[K     |████████████████████████████████| 71kB 30.5MB/s \n\u001b[?25hCollecting appdirs (from pyppeteer>=0.0.14->requests-html->twitter-scraper)\n  Downloading https://files.pythonhosted.org/packages/56/eb/810e700ed1349edde4cbdc1b2a21e28cdf115f9faf263f6bbf8447c1abf3/appdirs-1.4.3-py2.py3-none-any.whl\nRequirement already satisfied: tqdm in /usr/local/anaconda3/lib/python3.7/site-packages (from pyppeteer>=0.0.14->requests-html->twitter-scraper) (4.36.1)\nCollecting cssselect>0.7.9 (from pyquery->requests-html->twitter-scraper)\n  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\nRequirement already satisfied: lxml>=2.1 in /usr/local/anaconda3/lib/python3.7/site-packages (from pyquery->requests-html->twitter-scraper) (4.4.1)\nRequirement already satisfied: soupsieve>=1.2 in /usr/local/anaconda3/lib/python3.7/site-packages (from beautifulsoup4->bs4->requests-html->twitter-scraper) (1.9.3)\nBuilding wheels for collected packages: bs4, parse, pyppeteer, fake-useragent\n  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-cp37-none-any.whl size=1273 sha256=f05641e0ea94c2a1bcafa2a3b65aded9becdd9e337c370c9586bdb37b63a368b\n  Stored in directory: /Users/kennethreitz/Library/Caches/pip/wheels/a0/b0/b2/4f80b9456b87abedbc0bf2d52235414c3467d8889be38dd472\n  Building wheel for parse (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for parse: filename=parse-1.14.0-cp37-none-any.whl size=23463 sha256=6c96d7f7e09e837f25b219cf9b4c5fe66d9bbb32b4ce1d24b1ea5d1cf917de81\n  Stored in directory: /Users/kennethreitz/Library/Caches/pip/wheels/d7/07/e0/b74bfdc1d434e73ef79e69e301e82a7825e0c070f7442beb61\n  Building wheel for pyppeteer (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyppeteer: filename=pyppeteer-0.0.25-cp37-none-any.whl size=78362 sha256=36cb901fab580d2e1974cfc35a5837ef388d6b052331a635031cfbc15ed6b29c\n  Stored in directory: /Users/kennethreitz/Library/Caches/pip/wheels/34/e0/5d/070e22eceecf7ecd5fa4b86bbc18c1c7d0b90e02e9b57f35eb\n  Building wheel for fake-useragent (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-cp37-none-any.whl size=13485 sha256=e304279a828aa877d35a68fb17ceea73beb0e2d56b96631307008c8eb69d9bda\n  Stored in directory: /Users/kennethreitz/Library/Caches/pip/wheels/5e/63/09/d1dc15179f175357d3f5c00cbffbac37f9e8690d80545143ff\nSuccessfully built bs4 parse pyppeteer fake-useragent\nInstalling collected packages: w3lib, bs4, parse, pyee, websockets, appdirs, pyppeteer, cssselect, pyquery, fake-useragent, requests-html, twitter-scraper\nSuccessfully installed appdirs-1.4.3 bs4-0.0.1 cssselect-1.1.0 fake-useragent-0.1.11 parse-1.14.0 pyee-6.0.0 pyppeteer-0.0.25 pyquery-1.4.1 requests-html-0.10.0 twitter-scraper-0.3.0 w3lib-1.21.0 websockets-8.1\n"}],"source":["!pip install twitter-scraper"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"200 tweets found!\n"}],"source":["import twitter_scraper\n","\n","tweets = []\n","for tweet in twitter_scraper.get_tweets('kennethreitz', pages=10):\n","  tweets.append(tweet['text'])\n","  \n","\n","print(f\"{len(tweets)} tweets found!\")\n","tweets = '\\n'.join(tweets)\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: markovify in /usr/local/anaconda3/lib/python3.7/site-packages (0.8.0)\nRequirement already satisfied: unidecode in /usr/local/anaconda3/lib/python3.7/site-packages (from markovify) (1.1.1)\n"}],"source":["!pip install markovify"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Anyone want to be in the old days.\nAnd it doesn't properly sync all the time about the API of Requests.\nSorta like how I remember technical stuff best when I talk it through with someone.\nI think is one of my career precisely because they impart value.\nNot saying it’s a much needed tool for the way no one would help me.\nI think is one of my career precisely because they impart value.\nSorta like how I remember technical stuff best when I create art, I seek only perception of that which I art.\nI always, always forget just how good of a not retweet. https://twitter.com/kennethreitz/status/1204415364743880705 … Not a retweet.\nThe only reason it hasn’t shipped is no one offered to help me.\nSorta like how I remember technical stuff best when I talk it through with someone.\n"}],"source":["import markovify\n","\n","text_model = markovify.Text(tweets)\n","\n","for _ in range(10):\n","    print(text_model.make_short_sentence(140))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}